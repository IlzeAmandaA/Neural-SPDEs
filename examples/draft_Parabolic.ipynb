{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parabolic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1OS4xVMlMGfTikXtFLyH2ARsIuTGGahlm",
      "authorship_tag": "ABX9TyPNxngRU0K3ro95b4SqsjZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crispitagorico/Neural-SPDEs/blob/main/examples/draft_Parabolic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h1>Dynamic $\\Phi^4_1$ model</h1> </center>\n",
        "\n",
        "*The $\\Phi^4$-models describe phase transitions of ferromagnets and superconductors near critical temperatures.*\n",
        "\n",
        "*In this notebook we demonstrate that the Neural SPDE model is capable of learning dynamics described by the $\\Phi^4_1$ model,*\n",
        "\\begin{align}\n",
        "    \\partial_t u - \\Delta u &= 3u -u^3 + \\dot{\\xi}, && (t,x)\\in[0,T]\\times\\mathbb{T} \\nonumber\\\\\n",
        "    % u(t,0) &= u(t,1), && t\\in[0,1]\\\\\n",
        "    u(0,x) &= u_0(x)\n",
        "\\end{align}\n",
        "*with better accuracy and using only a modest amount of training data compared to all alternative models.*\n",
        "***"
      ],
      "metadata": {
        "id": "zhDh3Plj-jku"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4xBEJf_OER"
      },
      "source": [
        "!git clone \"https://github.com/crispitagorico/Neural-SPDEs.git\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0bc897O_RLN"
      },
      "source": [
        "%cd Neural-SPDEs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "knrYdNoHFWVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_ivsp8Tlvl"
      },
      "source": [
        "import torch\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from timeit import default_timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two cells below are for the format of the figures. "
      ],
      "metadata": {
        "id": "3MFp9HSn2WpQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnIiiDF2Dbwv"
      },
      "source": [
        "# # To avoid type 3 figures. This may take a long time\n",
        "# !sudo apt install texlive texlive-latex-extra texlive-fonts-recommended dvipng\n",
        "# !pip install latex\n",
        "# !sudo apt install cm-super"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Using seaborn's style\n",
        "# plt.style.use('seaborn-colorblind')\n",
        "# width = 345\n",
        "# tex_fonts = {\n",
        "#     \"text.usetex\": True,\n",
        "#     \"font.family\": \"serif\",\n",
        "#     \"axes.labelsize\": 24,\n",
        "#     \"font.size\": 24,\n",
        "#     \"legend.fontsize\": 24,\n",
        "#     \"xtick.labelsize\": 24,\n",
        "#     \"ytick.labelsize\": 24,\n",
        "# }\n",
        "# plt.rcParams.update(tex_fonts)"
      ],
      "metadata": {
        "id": "KFTt6_9Ew9Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pX2Ix-M-yXQ"
      },
      "source": [
        "**Load a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gu-1Pgyx4Xk"
      },
      "source": [
        "data = scipy.io.loadmat('../drive/MyDrive/Phi41+_xi_u0/Phi41+_u0_xi_{}.mat'.format(1200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = scipy.io.loadmat('../drive/MyDrive/Phi41+_xi_u0/Phi41+_xi_{}.mat'.format(1200))"
      ],
      "metadata": {
        "id": "GZT3w_zjHhSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has been saved in the following format\n",
        "\n",
        "* $O_X[j]=x_j$, \n",
        "* $O_T[k]=t_k$\n",
        "* $W[i,j,k]=\\xi^i(x_j,t_k), \\qquad i=1,\\ldots,N_\\text{train}+N_\\text{test}$\n",
        "* $Sol[i,j,k]=u^i(x_j,t_k), \\qquad i=1,\\ldots,N_\\text{train}+N_\\text{test}$\n",
        "\n"
      ],
      "metadata": {
        "id": "wq-gmNiX0H-z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thpe8tsjx8xp"
      },
      "source": [
        "O_X, O_T, W, Sol = data['X'], data['T'], data['W'], data['sol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi = torch.from_numpy(W.astype(np.float32))\n",
        "data = torch.from_numpy(Sol.astype(np.float32))"
      ],
      "metadata": {
        "id": "7J6huLIBwXGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTteH1Cn-rqh"
      },
      "source": [
        "# 1) Neural SPDE demo\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyING0iQ_yWC"
      },
      "source": [
        "import torch.optim as optim\n",
        "from utilities import dataloader_nspde_1d,train_nspde_1d, LpLoss, count_params\n",
        "from torchspde.neural_spde import NeuralSPDE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "n_1YYqEOwtE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**\n",
        "\n",
        "Specifying `dataset='phi41'` overrides $T$ and $sub_t$"
      ],
      "metadata": {
        "id": "_Nilj1XsxEcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = dataloader_nspde_1d(u=data, xi=xi, ntrain=1000, \n",
        "                                                ntest=200, T=51, sub_t=1, \n",
        "                                                batch_size=20, dim_x=128, \n",
        "                                                dataset='phi41')"
      ],
      "metadata": {
        "id": "188E_MinNLKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an NSPDE model**"
      ],
      "metadata": {
        "id": "FyCeu-noRPBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralSPDE(dim=1, in_channels=1, noise_channels=1, hidden_channels=16, \n",
        "                   n_iter=4, modes1=32, modes2=50).cuda()\n",
        "# model = NeuralSPDE(dim=1, in_channels=1, noise_channels=1, hidden_channels=16, \n",
        "#                    n_iter=4, modes1=32, solver='diffeq').cuda()"
      ],
      "metadata": {
        "id": "PRU5IoTEOJJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "_DcqduHzRFZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the NSPDE model**"
      ],
      "metadata": {
        "id": "bmq-njZDRTFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "s6sbMwP1OUPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_nspde_1d(model, train_loader, test_loader, \n",
        "                                                 device, loss, batch_size=20, epochs=5000, \n",
        "                                                  learning_rate=0.001, scheduler_step=100, \n",
        "                                                  scheduler_gamma=0.5, print_every=5)"
      ],
      "metadata": {
        "id": "hex8Cr9hOAQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(1,len(losses_train)*5, 5), losses_train, label='train')\n",
        "plt.plot(np.arange(1,len(losses_test)*5, 5), losses_test, label='test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Relative L2 loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHHZ_62TPhKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize predictions**"
      ],
      "metadata": {
        "id": "Omaau1fHx_gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utilities import plot_1d, contour_plot_1d"
      ],
      "metadata": {
        "id": "BcqCDsfKKzEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_1d(model, test_loader, device, i=1, T_=5, T=51, a=1)\n"
      ],
      "metadata": {
        "id": "iseTSTOOx-Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contour_plot_1d(model, test_loader, device, O_X[0,:-1], O_T[0,:51])"
      ],
      "metadata": {
        "id": "4U0Sr-J0InjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGUrcdPyr4K8"
      },
      "source": [
        "**Memory profiling** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kurZF8o2dimf"
      },
      "source": [
        "mem_log = []\n",
        "for u0_, xi_, u_ in train_loader:\n",
        "    input = u0_.to(device), xi_.to(device)\n",
        "    break\n",
        "try:\n",
        "    mem_log.extend(log_mem(model, input, exp='baseline'))\n",
        "except Exception as e:\n",
        "    print(f'log_mem failed because of {e}')\n",
        "    \n",
        "df = pd.DataFrame(mem_log)\n",
        "plot_mem(df, exps=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAyQKWMnysL9"
      },
      "source": [
        "**Super-resolution demonstration**\n",
        "\n",
        "We start by loading a dataset with a finer spatial resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn8FqaNkRP5T"
      },
      "source": [
        "batch_size = 20\n",
        "ntest = 200\n",
        "\n",
        "data = scipy.io.loadmat('../drive/MyDrive/Phi41+_xi_u0/Phi41+_u0_xi_super_{}.mat'.format(ntest))\n",
        "\n",
        "_, test_loader = dataloader_nspde_1d(u=data, xi=xi, ntrain=100, ntest=200, batch_size=batch_size, \n",
        "                                     dim_x=128, dataset='phi41')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we load a model which has been trained on a lower resolution"
      ],
      "metadata": {
        "id": "eox8MoBM49Mu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2lW4bT_yBNA"
      },
      "source": [
        "model = NeuralSPDE(dim=1, in_channels=1, noise_channels=1, hidden_channels=16, \n",
        "                   n_iter=4, modes1=32, modes2=50).cuda()\n",
        "model.load_state_dict(torch.load('model.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we evaluate the model on the finer resolution dataset"
      ],
      "metadata": {
        "id": "xJ3eknul5FBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "test_loss = 0.\n",
        "with torch.no_grad():\n",
        "    for u0_, xi_, u_ in test_loader:    \n",
        "        loss = 0.       \n",
        "        u0_, xi_, u_ = u0_.to(device), xi_.to(device), u_.to(device)\n",
        "        u_pred = model(u0_, xi_)\n",
        "        loss = myloss(u_pred.reshape(batch_size, -1), u_.reshape(batch_size, -1))\n",
        "        test_loss += loss.item()\n",
        "print('Super-resolution test Loss {:.6f} with {} spatial points'.format(test_loss / ntest, \n",
        "                                                                        xi_.shape[-2]))"
      ],
      "metadata": {
        "id": "Y-28_4Wu5Dga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Baselines\n",
        "***"
      ],
      "metadata": {
        "id": "7Ygs_ELDQ57A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0_jmj60HpNw"
      },
      "source": [
        "### FNO (space-time FFT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Brb_By8IV-x"
      },
      "source": [
        "from baselines.fourier_space1d_time import FNO_space1D_time, dataloader_fno_1d_xi, dataloader_fno_1d_u0, train_fno_1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**\n",
        "\n",
        "There are two different dataloaders. One is when we want to learn the map $u_0|_{O_X}\\mapsto u|_{O_X\\times O_T}$. The other one is when we want to learn the map $\\xi|_{O_X\\times O_T}\\mapsto u|_{O_X\\times O_T}$"
      ],
      "metadata": {
        "id": "6O8i6GWQ7fVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = dataloader_fno_1d_xi(u=data, xi=xi, ntrain=1000, \n",
        "                                                 ntest=200, T=51, sub_t=1, batch_size=20, \n",
        "                                                 dim_x=128, dataset='phi41')"
      ],
      "metadata": {
        "id": "V2VYzYFx7YCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader, test_loader = dataloader_fno_1d_u0(u=data, ntrain=1000, \n",
        "#                                                  ntest=200, T=51, sub_t=1, batch_size=20, \n",
        "#                                                  dim_x=128, dataset='phi41')"
      ],
      "metadata": {
        "id": "M9fKP3Uk9coe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an FNO model**\n",
        "\n",
        "One needs to specify the number of observations in time for the input. When the input is the forcing $T>1$ (e.g. here $T=51$) and when the input is the initial condition $T=1$"
      ],
      "metadata": {
        "id": "Z5rpa5ae7j20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FNO_space1D_time(modes1=32, modes2=24, width=32, T=1, L=4).cuda()"
      ],
      "metadata": {
        "id": "G_aPKqkh7mdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "iHHlYQBM7op_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the FNO model**"
      ],
      "metadata": {
        "id": "z81bM6qb7pVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "bJ5MXtyL7pp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_fno_1d(model, train_loader, test_loader, \n",
        "                                                device, loss, batch_size=20, epochs=5000, \n",
        "                                                learning_rate=0.001, scheduler_step=100, \n",
        "                                                scheduler_gamma=0.5, print_every=5)"
      ],
      "metadata": {
        "id": "i_UD-8de7ukl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFy8Ibdp3Ar1"
      },
      "source": [
        "**Memory profiling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FnKIQJO290A"
      },
      "source": [
        "mem_log = []\n",
        "for xi_, u_ in train_loader:\n",
        "    input = xi_.to(device)\n",
        "    break\n",
        "try:\n",
        "    mem_log.extend(log_mem(model, input, exp='baseline', model_type='FNO'))\n",
        "except Exception as e:\n",
        "    print(f'log_mem failed because of {e}')\n",
        "    \n",
        "df = pd.DataFrame(mem_log)\n",
        "plot_mem(df, exps=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQnMsvoalrd"
      },
      "source": [
        "###NCDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgEaME6Pqwk"
      },
      "source": [
        "from baselines.NCDE import NeuralCDE, dataloader_ncde_1d, train_ncde_1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**"
      ],
      "metadata": {
        "id": "fpouM5bd-MVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_x = 128\n",
        "train_loader, test_loader, normalizer = dataloader_ncde_1d(u=data, xi=xi, ntrain=1000, \n",
        "                                                           ntest=200, T=51, sub_t=1, \n",
        "                                                           batch_size=20, dim_x=dim_x, \n",
        "                                                           normalizer=True, interpolation='linear',\n",
        "                                                           dataset='phi41')"
      ],
      "metadata": {
        "id": "0H3hgocX-MVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an NCDE model**\n"
      ],
      "metadata": {
        "id": "N62531Ze-MVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralCDE(input_channels=dim_x+1, hidden_channels=16, output_channels=dim_x, \n",
        "                  interpolation='linear').cuda()"
      ],
      "metadata": {
        "id": "7BGWbKf4-MVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "q9j7rabe-MVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the NCDE model**"
      ],
      "metadata": {
        "id": "YgsBzGx9-MVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "xJ_n_r-B-MVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_ncde_1d(model, train_loader, test_loader, normalizer,\n",
        "                                                device, loss, batch_size=20, epochs=5000, \n",
        "                                                learning_rate=0.001, scheduler_step=100, \n",
        "                                                scheduler_gamma=0.5, print_every=1)"
      ],
      "metadata": {
        "id": "zjlfa3qk-MVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBtNj0P_2jDp"
      },
      "source": [
        "mem_log = []\n",
        "for u0_, xi_, u_ in train_loader:\n",
        "    input = u0_.to(device), xi_.to(device)\n",
        "    break\n",
        "try:\n",
        "    mem_log.extend(log_mem(model, input, exp='baseline'))\n",
        "except Exception as e:\n",
        "    print(f'log_mem failed because of {e}')\n",
        "\n",
        "df = pd.DataFrame(mem_log)\n",
        "plot_mem(df, exps=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BmNjo-sKM-Z"
      },
      "source": [
        "#NRDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsqGjCcxKNRP"
      },
      "source": [
        "from baselines.NRDE import NeuralRDE, dataloader_nrde_1d, train_nrde_1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0nILQfLL5Jk"
      },
      "source": [
        "import signatory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_fNtTbrKXR2"
      },
      "source": [
        "print(count_params(model))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**"
      ],
      "metadata": {
        "id": "1cRXW2ylDGI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_x = 128\n",
        "train_load, test_load, I, noise_size, norm = dataloader_nrde_1d(u=data, xi=xi, ntrain=1000, \n",
        "                                                                ntest=200, T=51, sub_t=1, \n",
        "                                                                batch_size=20, dim_x=dim_x, \n",
        "                                                                depth=2, window_length=10, \n",
        "                                                                normalizer=True, \n",
        "                                                                interpolation='linear',\n",
        "                                                                dataset='phi41')"
      ],
      "metadata": {
        "id": "MbQBsLM7DGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an NRDE model**\n"
      ],
      "metadata": {
        "id": "ZqDwHuh6DGI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralRDE(control_channels=noise_size, input_channels=dim_x, \n",
        "                  hidden_channels=2, output_channels=dim_x, interval=I, \n",
        "                  interpolation='linear').cuda()"
      ],
      "metadata": {
        "id": "LEluWgaaDGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "y7mEr0dXDGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the NRDE model**"
      ],
      "metadata": {
        "id": "Yn41djgFDGI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "jUwdFbfJDGI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_nrde_1d(model, train_load, test_load, norm,\n",
        "                                                device, loss, batch_size=20, epochs=5000, \n",
        "                                                learning_rate=0.001, scheduler_step=100, \n",
        "                                                scheduler_gamma=0.5, print_every=1)"
      ],
      "metadata": {
        "id": "ScBVD1knDGI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlnGq712cEK3"
      },
      "source": [
        "### NCDE-FNO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kahPuu-VsXOT"
      },
      "source": [
        "from baselines.NCDEinf_1D import NeuralCDE, dataloader_ncdeinf_1d, train_ncdeinf_1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**"
      ],
      "metadata": {
        "id": "Z_SCrBInFWNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = dataloader_ncdeinf_1d(data, xi, ntrain=1000, ntest=200, T=51, \n",
        "                                                  sub_t=1, batch_size=20, dim_x=128, \n",
        "                                                  interpolation='linear', dataset=None)"
      ],
      "metadata": {
        "id": "-GmaBHZVFWNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an NCDE-FNO model**\n"
      ],
      "metadata": {
        "id": "MJe7Z3OHFWNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralCDE(data_size=1, noise_size=1, hidden_channels=32, output_channels=1, \n",
        "                  interpolation='linear').cuda()"
      ],
      "metadata": {
        "id": "Jxzhi-nYFWNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "8F2MOFArFWNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the NCDE-FNO model**"
      ],
      "metadata": {
        "id": "HzP91bAjFWNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "9FHXg65_FWNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_ncdeinf_1d(model, train_loader, test_loader, \n",
        "                                                    device, loss, batch_size=20, epochs=5000, \n",
        "                                                    learning_rate=0.001, scheduler_step=100, \n",
        "                                                    scheduler_gamma=0.5, print_every=1)"
      ],
      "metadata": {
        "id": "DnAgVw_JFWNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhUo_kW2MuY"
      },
      "source": [
        "**Memory profiling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e1vOQgS2Imv"
      },
      "source": [
        "mem_log = []\n",
        "for u0_, xi_, u_ in train_loader:\n",
        "    input = u0_.to(device), xi_.to(device)\n",
        "    break\n",
        "try:\n",
        "    mem_log.extend(log_mem(model, input, exp='baseline'))\n",
        "except Exception as e:\n",
        "    print(f'log_mem failed because of {e}')\n",
        "\n",
        "df = pd.DataFrame(mem_log)\n",
        "plot_mem(df, exps=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElwqsKPPfoG8"
      },
      "source": [
        "### DeepONet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from baselines.deepOnet import DeepONetCP, dataloader_deeponet_1d_u0, train_deepOnet_1d"
      ],
      "metadata": {
        "id": "hk_9VvoaA2MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataloaders**"
      ],
      "metadata": {
        "id": "QU8N5wNmAwPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader, grid = dataloader_deeponet_1d_xi(data, xi, ntrain=1000, ntest=200, \n",
        "                                                            T=51, sub_t=1, batch_size=20, \n",
        "                                                            dim_x=128, normalizer=False, \n",
        "                                                            dataset=None)"
      ],
      "metadata": {
        "id": "kutqrr6aAwPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader, grid = dataloader_deeponet_1d_u0(data, ntrain=1000, ntest=200, \n",
        "                                                            T=51, sub_t=1, batch_size=20, \n",
        "                                                            dim_x=128, normalizer=False, \n",
        "                                                            dataset=None)"
      ],
      "metadata": {
        "id": "dMeitdXlBFlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an deepOnet model**\n"
      ],
      "metadata": {
        "id": "xZL4qCAfAwPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepONetCP(branch_layer=[S] + [300, 200],\n",
        "                    trunk_layer=[2] + [100, 200, 200]).to(device)\n",
        "# model = DeepONetCP(branch_layer=[S*101] + [30, 30],\n",
        "#                     trunk_layer=[2] + [30, 30]).to(device)"
      ],
      "metadata": {
        "id": "NEoxgstCAwPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The model has {} parameters'. format(count_params(model)))"
      ],
      "metadata": {
        "id": "3kT4JqJ9AwPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the deepOnet model**"
      ],
      "metadata": {
        "id": "HXD9-qaAAwPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LpLoss(size_average=False)"
      ],
      "metadata": {
        "id": "MU9VfttaAwPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_train, losses_test = train_deepOnet_1d(model, train_loader, test_loader, grid,\n",
        "                                                    normalizer, device, loss, batch_size=20, \n",
        "                                                    epochs=500, learning_rate=0.001, \n",
        "                                                    scheduler_step=100, scheduler_gamma=0.5, \n",
        "                                                    print_every=1)"
      ],
      "metadata": {
        "id": "iw3u8A3mAwPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}